@inproceedings{tatt,
  title={A text attention network for spatial deformation robust scene text image super-resolution},
  author={Ma, Jianqi and Liang, Zhetong and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5911--5920},
  year={2022}
}

@inproceedings{dpmn,
  title={Improving scene text image super-resolution via dual prior modulation network},
  author={Zhu, Shipeng and Zhao, Zuoyan and Fang, Pengfei and Xue, Hui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={3},
  pages={3843--3851},
  year={2023}
}

@inproceedings{abinet,
  title={Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition},
  author={Fang, Shancheng and Xie, Hongtao and Wang, Yuxin and Mao, Zhendong and Zhang, Yongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7098--7107},
  year={2021}
}

@article{clip4str,
  title={Clip4str: A simple baseline for scene text recognition with pre-trained vision-language model},
  author={Zhao, Shuai and Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  journal={arXiv preprint arXiv:2305.14014},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{dpan,
  title={Look back again: Dual parallel attention network for accurate and robust scene text recognition},
  author={Fu, Zilong and Xie, Hongtao and Jin, Guoqing and Guo, Junbo},
  booktitle={Proceedings of the 2021 International Conference on Multimedia Retrieval},
  pages={638--644},
  year={2021}
}

@inproceedings{mgp-str,
  title={Multi-granularity prediction for scene text recognition},
  author={Wang, Peng and Da, Cheng and Yao, Cong},
  booktitle={European Conference on Computer Vision},
  pages={339--355},
  year={2022},
  organization={Springer}
}

@inproceedings{parseq,
  title={Scene text recognition with permuted autoregressive sequence models},
  author={Bautista, Darwin and Atienza, Rowel},
  booktitle={European conference on computer vision},
  pages={178--196},
  year={2022},
  organization={Springer}
}

@misc{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{svtr,
      title={SVTR: Scene Text Recognition with a Single Visual Model}, 
      author={Yongkun Du and Zhineng Chen and Caiyan Jia and Xiaoting Yin and Tianlun Zheng and Chenxia Li and Yuning Du and Yu-Gang Jiang},
      year={2022},
      eprint={2205.00159},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{aster,
  title     = {Aster: An attentional scene text recognizer with flexible rectification},
  author    = {Shi, Baoguang and Yang, Mingkun and Wang, Xinggang and Lyu, Pengyuan and Yao, Cong and Bai, Xiang},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {41},
  number    = {9},
  pages     = {2035--2048},
  year      = {2018},
  publisher = {IEEE}
}

@article{gru,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@inproceedings{tsrn,
  title        = {Scene text image super-resolution in the wild},
  author       = {Wang, Wenjia and Xie, Enze and Liu, Xuebo and Wang, Wenhai and Liang, Ding and Shen, Chunhua and Bai, Xiang},
  booktitle    = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part X 16},
  pages        = {650--666},
  year         = {2020},
  organization = {Springer}
}

@misc{coco-text,
  title         = {COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images},
  author        = {Andreas Veit and Tomas Matera and Lukas Neumann and Jiri Matas and Serge Belongie},
  year          = {2016},
  eprint        = {1601.07140},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{icdar2013,
  title        = {ICDAR 2013 robust reading competition},
  author       = {Karatzas, Dimosthenis and Shafait, Faisal and Uchida, Seiichi and Iwamura, Masakazu and i Bigorda, Lluis Gomez and Mestre, Sergi Robles and Mas, Joan and Mota, David Fernandez and Almazan, Jon Almazan and De Las Heras, Lluis Pere},
  booktitle    = {2013 12th international conference on document analysis and recognition},
  pages        = {1484--1493},
  year         = {2013},
  organization = {IEEE}
}

@article{cute80,
  title     = {A robust arbitrary text detection system for natural scene images},
  author    = {Risnumawan, Anhar and Shivakumara, Palaiahankote and Chan, Chee Seng and Tan, Chew Lim},
  journal   = {Expert Systems with Applications},
  volume    = {41},
  number    = {18},
  pages     = {8027--8048},
  year      = {2014},
  publisher = {Elsevier}
}

@misc{crnn,
      title={An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition}, 
      author={Baoguang Shi and Xiang Bai and Cong Yao},
      year={2015},
      eprint={1507.05717},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{ctc,
author = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
title = {Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143891},
doi = {10.1145/1143844.1143891},
abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {369–376},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}

@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = {nov},
pages = {1735–1780},
numpages = {46}
}