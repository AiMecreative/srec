@article{mish,
  title={Mish: A self regularized non-monotonic activation function},
  author={Misra, Diganta},
  journal={arXiv preprint arXiv:1908.08681},
  year={2019}
}

@article{uncertainty-loss-2,
  title={Auxiliary tasks in multi-task learning},
  author={Liebel, Lukas and K{\"o}rner, Marco},
  journal={arXiv preprint arXiv:1805.06334},
  year={2018}
}

@inproceedings{ctcloss,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{uncertainty-loss,
  title={Multi-task learning using uncertainty to weigh losses for scene geometry and semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7482--7491},
  year={2018}
}

@inproceedings{gpp,
  title={Image super-resolution using gradient profile prior},
  author={Sun, Jian and Xu, Zongben and Shum, Heung-Yeung},
  booktitle={2008 IEEE conference on computer vision and pattern recognition},
  pages={1--8},
  year={2008},
  organization={IEEE}
}

@inproceedings{synthtext,
  title={Synthetic data for text localisation in natural images},
  author={Gupta, Ankush and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2315--2324},
  year={2016}
}

@article{mjsynth,
  title={Reading text in the wild with convolutional neural networks},
  author={Jaderberg, Max and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={116},
  pages={1--20},
  year={2016},
  publisher={Springer}
}

@article{stn,
  title   = {Spatial transformer networks},
  author  = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},
  journal = {Advances in neural information processing systems},
  volume  = {28},
  year    = {2015}
}

@article{tps,
  title     = {Principal warps: Thin-plate splines and the decomposition of deformations},
  author    = {Bookstein, Fred L.},
  journal   = {IEEE Transactions on pattern analysis and machine intelligence},
  volume    = {11},
  number    = {6},
  pages     = {567--585},
  year      = {1989},
  publisher = {IEEE}
}

@inproceedings{sr-raw,
  title     = {Zoom to learn, learn to zoom},
  author    = {Zhang, Xuaner and Chen, Qifeng and Ng, Ren and Koltun, Vladlen},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {3762--3770},
  year      = {2019}
}

@inproceedings{realsr,
  author    = {Ji, Xiaozhong and Cao, Yun and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title     = {Real-World Super-Resolution via Kernel Estimation and Noise Injection},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1914-1923},
  keywords  = {Kernel;Degradation;Data models;Training;Estimation;Spatial resolution},
  doi       = {10.1109/CVPRW50498.2020.00241}
}


@article{textdiff,
  title   = {TextDiff: Mask-Guided Residual Diffusion Models for Scene Text Image Super-Resolution},
  author  = {Liu, Baolin and Yang, Zongyuan and Wang, Pengfei and Zhou, Junjie and Liu, Ziqi and Song, Ziyi and Liu, Yan and Xiong, Yongping},
  journal = {arXiv preprint arXiv:2308.06743},
  year    = {2023}
}

@article{sr3,
  title     = {Image super-resolution via iterative refinement},
  author    = {Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {45},
  number    = {4},
  pages     = {4713--4726},
  year      = {2022},
  publisher = {IEEE}
}

@article{ddpm,
  title   = {Denoising diffusion probabilistic models},
  author  = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal = {Advances in neural information processing systems},
  volume  = {33},
  pages   = {6840--6851},
  year    = {2020}
}

@article{c3,
  title   = {C3-stisr: Scene text image super-resolution with triple clues},
  author  = {Zhao, Minyi and Wang, Miao and Bai, Fan and Li, Bingjia and Wang, Jie and Zhou, Shuigeng},
  journal = {arXiv preprint arXiv:2204.14044},
  year    = {2022}
}

@inproceedings{stt,
  title     = {Text gestalt: Stroke-aware scene text image super-resolution},
  author    = {Chen, Jingye and Yu, Haiyang and Ma, Jianqi and Li, Bin and Xue, Xiangyang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {36},
  number    = {1},
  pages     = {285--293},
  year      = {2022}
}

@inproceedings{pcan,
  author    = {Zhao, Cairong and Feng, Shuyang and Zhao, Brian Nlong and Ding, Zhijun and Wu, Jun and Shen, Fumin and Shen, Heng Tao},
  title     = {Scene Text Image Super-Resolution via Parallelly Contextual Attention Network},
  year      = {2021},
  isbn      = {9781450386517},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3474085.3475469},
  doi       = {10.1145/3474085.3475469},
  abstract  = {Optical degradation blurs text shapes and edges, so existing scene text recognition methods have difficulties in achieving desirable results on low-resolution (LR) scene text images acquired in real-world environments. The above problem can be solved by efficiently extracting sequential information to reconstruct super-resolution (SR) text images, which remains a challenging task. In this paper, we propose a Parallelly Contextual Attention Network (PCAN), which effectively learns sequence-dependent features and focuses more on high-frequency information of the reconstruction in text images. Firstly, we explore the importance of sequence-dependent features in horizontal and vertical directions parallelly for text SR, and then design a parallelly contextual attention block to adaptively select the key information in the text sequence that contributes to image super-resolution. Secondly, we propose a hierarchically orthogonal texture-aware attention module and an edge guidance loss function, which can help to reconstruct high-frequency information in text images. Finally, we conduct extensive experiments on TextZoom dataset, and the results can be easily incorporated into mainstream text recognition algorithms to further improve their performance in LR image recognition. Besides, our approach exhibits great robustness in defending against adversarial attacks on seven mainstream scene text recognition datasets, which means it can also improve the security of the text recognition pipeline. Compared with directly recognizing LR images, our method can respectively improve the recognition accuracy of ASTER, MORAN, and CRNN by 14.9\%, 14.0\%, and 20.1\%. Our method outperforms eleven state-of-the-art (SOTA) SR methods in terms of boosting text recognition performance. Most importantly, it outperforms the current optimal text-orient SR method TSRN by 3.2\%, 3.7\%, and 6.0\% on the recognition accuracy of ASTER, MORAN, and CRNN respectively.},
  booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
  pages     = {2908–2917},
  numpages  = {10},
  keywords  = {attention, boundary, scene text, sequential information, super-resolution},
  location  = {Virtual Event, China},
  series    = {MM '21}
}

@article{tpgsr,
  author   = {Ma, Jianqi and Guo, Shi and Zhang, Lei},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Text Prior Guided Scene Text Image Super-Resolution},
  year     = {2023},
  volume   = {32},
  number   = {},
  pages    = {1341-1353},
  keywords = {Text recognition;Superresolution;Image recognition;Visualization;Image resolution;Generators;Feature extraction;Scene text image super-resolution;super-resolution;text prior},
  doi      = {10.1109/TIP.2023.3237002}
}


@inproceedings{pixelshuffle,
  title     = {Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network},
  author    = {Shi, Wenzhe and Caballero, Jose and Husz{\'a}r, Ferenc and Totz, Johannes and Aitken, Andrew P and Bishop, Rob and Rueckert, Daniel and Wang, Zehan},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {1874--1883},
  year      = {2016}
}

@inproceedings{tatt,
  title     = {A text attention network for spatial deformation robust scene text image super-resolution},
  author    = {Ma, Jianqi and Liang, Zhetong and Zhang, Lei},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {5911--5920},
  year      = {2022}
}

@inproceedings{dpmn,
  title     = {Improving scene text image super-resolution via dual prior modulation network},
  author    = {Zhu, Shipeng and Zhao, Zuoyan and Fang, Pengfei and Xue, Hui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {37},
  number    = {3},
  pages     = {3843--3851},
  year      = {2023}
}

@inproceedings{abinet,
  title     = {Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition},
  author    = {Fang, Shancheng and Xie, Hongtao and Wang, Yuxin and Mao, Zhendong and Zhang, Yongdong},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {7098--7107},
  year      = {2021}
}

@article{clip4str,
  title   = {Clip4str: A simple baseline for scene text recognition with pre-trained vision-language model},
  author  = {Zhao, Shuai and Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  journal = {arXiv preprint arXiv:2305.14014},
  year    = {2023}
}

@inproceedings{clip,
  title        = {Learning transferable visual models from natural language supervision},
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle    = {International conference on machine learning},
  pages        = {8748--8763},
  year         = {2021},
  organization = {PMLR}
}

@article{gpt3,
  title   = {Language models are few-shot learners},
  author  = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal = {Advances in neural information processing systems},
  volume  = {33},
  pages   = {1877--1901},
  year    = {2020}
}

@article{gpt,
  title     = {Improving language understanding by generative pre-training},
  author    = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year      = {2018},
  publisher = {OpenAI}
}

@article{bert,
  title   = {Bert: Pre-training of deep bidirectional transformers for language understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal = {arXiv preprint arXiv:1810.04805},
  year    = {2018}
}

@article{transformer,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@inproceedings{dpan,
  title     = {Look back again: Dual parallel attention network for accurate and robust scene text recognition},
  author    = {Fu, Zilong and Xie, Hongtao and Jin, Guoqing and Guo, Junbo},
  booktitle = {Proceedings of the 2021 International Conference on Multimedia Retrieval},
  pages     = {638--644},
  year      = {2021}
}

@inproceedings{mgp-str,
  title        = {Multi-granularity prediction for scene text recognition},
  author       = {Wang, Peng and Da, Cheng and Yao, Cong},
  booktitle    = {European Conference on Computer Vision},
  pages        = {339--355},
  year         = {2022},
  organization = {Springer}
}

@inproceedings{parseq,
  title        = {Scene text recognition with permuted autoregressive sequence models},
  author       = {Bautista, Darwin and Atienza, Rowel},
  booktitle    = {European conference on computer vision},
  pages        = {178--196},
  year         = {2022},
  organization = {Springer}
}

@misc{vit,
  title         = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author        = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  year          = {2021},
  eprint        = {2010.11929},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{svtr,
  title         = {SVTR: Scene Text Recognition with a Single Visual Model},
  author        = {Yongkun Du and Zhineng Chen and Caiyan Jia and Xiaoting Yin and Tianlun Zheng and Chenxia Li and Yuning Du and Yu-Gang Jiang},
  year          = {2022},
  eprint        = {2205.00159},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{aster,
  title     = {Aster: An attentional scene text recognizer with flexible rectification},
  author    = {Shi, Baoguang and Yang, Mingkun and Wang, Xinggang and Lyu, Pengyuan and Yao, Cong and Bai, Xiang},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {41},
  number    = {9},
  pages     = {2035--2048},
  year      = {2018},
  publisher = {IEEE}
}

@article{gru,
  title   = {Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author  = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1406.1078},
  year    = {2014}
}

@inproceedings{tsrn,
  title        = {Scene text image super-resolution in the wild},
  author       = {Wang, Wenjia and Xie, Enze and Liu, Xuebo and Wang, Wenhai and Liang, Ding and Shen, Chunhua and Bai, Xiang},
  booktitle    = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part X 16},
  pages        = {650--666},
  year         = {2020},
  organization = {Springer}
}

@misc{coco-text,
  title         = {COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images},
  author        = {Andreas Veit and Tomas Matera and Lukas Neumann and Jiri Matas and Serge Belongie},
  year          = {2016},
  eprint        = {1601.07140},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{icdar2013,
  title        = {ICDAR 2013 robust reading competition},
  author       = {Karatzas, Dimosthenis and Shafait, Faisal and Uchida, Seiichi and Iwamura, Masakazu and i Bigorda, Lluis Gomez and Mestre, Sergi Robles and Mas, Joan and Mota, David Fernandez and Almazan, Jon Almazan and De Las Heras, Lluis Pere},
  booktitle    = {2013 12th international conference on document analysis and recognition},
  pages        = {1484--1493},
  year         = {2013},
  organization = {IEEE}
}

@article{cute80,
  title     = {A robust arbitrary text detection system for natural scene images},
  author    = {Risnumawan, Anhar and Shivakumara, Palaiahankote and Chan, Chee Seng and Tan, Chew Lim},
  journal   = {Expert Systems with Applications},
  volume    = {41},
  number    = {18},
  pages     = {8027--8048},
  year      = {2014},
  publisher = {Elsevier}
}

@misc{crnn,
  title         = {An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition},
  author        = {Baoguang Shi and Xiang Bai and Cong Yao},
  year          = {2015},
  eprint        = {1507.05717},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{ctc,
  author    = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
  title     = {Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  year      = {2006},
  isbn      = {1595933832},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1143844.1143891},
  doi       = {10.1145/1143844.1143891},
  abstract  = {Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.},
  booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
  pages     = {369–376},
  numpages  = {8},
  location  = {Pittsburgh, Pennsylvania, USA},
  series    = {ICML '06}
}

@article{lstm,
  author     = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
  title      = {Long Short-Term Memory},
  year       = {1997},
  issue_date = {November 15, 1997},
  publisher  = {MIT Press},
  address    = {Cambridge, MA, USA},
  volume     = {9},
  number     = {8},
  issn       = {0899-7667},
  url        = {https://doi.org/10.1162/neco.1997.9.8.1735},
  doi        = {10.1162/neco.1997.9.8.1735},
  abstract   = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  journal    = {Neural Comput.},
  month      = {nov},
  pages      = {1735–1780},
  numpages   = {46}
}